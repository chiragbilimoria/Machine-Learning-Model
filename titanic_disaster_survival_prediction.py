# -*- coding: utf-8 -*-
"""Titanic_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h4cx2lPwCP12ARwmtqCjT5ygXZ0wG0bP
"""

"""**Importing Libraries**"""
import pandas as pd
import numpy as np
import sys
np.set_printoptions(threshold=sys.maxsize)
pip install scikit-plot



"""**Importing Data**"""
df=pd.read_csv('https://www.kaggle.com/c/titanic/data?select=train.csv.csv')

df1=pd.read_csv('https://www.kaggle.com/c/titanic/data?select=test.csv')

df1

"""**Performing Statistical Analysis on Data**"""

df.describe()

data_crosstab = pd.crosstab(df['Sex'], 
                            df['Survived'],  
                               margins = False) 
print(data_crosstab)

data_crosstab = pd.crosstab(df['Sex'], 
                            df['Pclass'],  
                               margins = False) 
print(data_crosstab)

data_crosstab = pd.crosstab(df['Sex'], 
                            df['SibSp'],  
                               margins = False) 
print(data_crosstab)

data_crosstab = pd.crosstab(df['Sex'], 
                            df['Parch'],  
                               margins = False) 
print(data_crosstab)

df.info

df.groupby('Sex').count()

df['Sex'].value_counts()

df['Pclass'].value_counts()

df['Embarked'].value_counts()

df['Survived'].value_counts()

df['SibSp'].value_counts()

df.hist(column='Age')

df.hist(column='Fare')

df.boxplot(column='Age')

df.boxplot(column='Fare')

df.nlargest(5,'Fare')

df.nsmallest(5,'Fare')

#Creating set of Independent variables training data
X=df.loc[:, ['Pclass', 'Sex','Embarked','Age','SibSp','Parch','Fare']].values

#Creating set of Independent variables for test data
X1=df1.loc[:, ['Pclass', 'Sex','Embarked','Age','SibSp','Parch','Fare']].values

#Dependent varibale for traing data
pass_id=df1.loc[:,['PassengerId']].values

#Dependent varibale for traing data
Y=df.loc[:,['Survived']].values

print(X)

print(Y)

df1.isna().sum()

"""**Data Preprocessing**"""

#Imputing Missing data Values with mean values for training data
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
imputer.fit(X[:,3:4])
X[:,3:4] = imputer.transform(X[:,3:4])
print(X)

#Imputing Missing data Values  with mean values for testing data
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
imputer.fit(X1[:,3:])
X1[:,3:] = imputer.transform(X1[:,3:])
print(X1)

# Imputing missing categorical data values with most frequent values
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
imputer.fit(X[:,2:3])
X[:,2:3] = imputer.transform(X[:,2:3])
print(X)

# Encoding the Independent Variable
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(categories='auto'),[0,1,2])], remainder='passthrough')
#bt = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')
#at = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2])], remainder='passthrough')
X = np.array(ct.fit_transform(X))
#X = np.array(bt.fit_transform(X))
#X = np.array(at.fit_transform(X))
print(X)

# Encoding the Independent Variable for testing data
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(categories='auto'),[0,1,2])], remainder='passthrough')
#bt = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')
#at = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2])], remainder='passthrough')
X1 = np.array(ct.fit_transform(X1))
#X = np.array(bt.fit_transform(X))
#X = np.array(at.fit_transform(X))
print(X1)

# spliting train dataset into training and testing data of training data set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)
print(X_train)
print(y_train)
print(X_test)
print(y_test)

"""**Model Building**"""

# Training the Logistic Regression model on the Training set
from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 0)
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred = classifier.predict(X_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

#getting coefficient values 
classifier.coef_

# Training the Random Forest model on the Training set
from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)

# Predicting the Test set results on training data set
y_pred = classifier.predict(X_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

# Predicting the Test set results on test dataset
y_pred = classifier.predict(X1)

# Making the Confusion Matrix for Random Forest Model
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

# Predicting the Test set results on test dataset on Random forest model
y_pred_res = classifier.predict(X1)

#print test results
print(y_pred_res.reshape(len(y_pred),1))

#Importing Libraries
from sklearn import metrics
import scikitplot as skplt
import matplotlib.pyplot as plt

#Calculating Thresholds
fpr,tpr,thresholds = metrics.roc_curve(y_test,y_pred,pos_label=0)

#Plotting AUC curve
plt.plot(fpr,tpr)
plt.show()

#Calculating AUC value
auc=np.trapz(tpr,fpr)
print('AUC:',auc)

#Calculating ROC value
probs=classifier.predict_proba(X_test)
preds=probs[:,1]
fpr,tpr,threshold=metrics.roc_curve(y_test,preds)
roc_auc=metrics.auc(fpr,tpr)

#Calculated ROC value
roc_auc

#plotting ROC curve
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

#merging Test data with predicted value a
results=np.column_stack((pass_id,y_pred_res.reshape(len(y_pred),1)))

results

#Creating dataframe
df_results = pd.DataFrame(data=df_res, columns=["PassengerId", "Survived"])

df_results

#Exporting dataframe for submission
df_results.to_csv('Survival_Pred.csv')